#!/usr/bin/env python3
"""
éƒ¨ç½²éªŒè¯è„šæœ¬

ç”¨äºéªŒè¯ Nitter X é¡¹ç›®åœ¨æ–°ç¯å¢ƒä¸­çš„éƒ¨ç½²çŠ¶æ€
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

from src.storage.postgres_client import get_postgres_client
from src.storage.redis_client import get_redis_client
from src.utils.logger import setup_logger

logger = setup_logger("deployment_check", log_file="logs/deployment_check.log")


def check_database():
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œè¡¨ç»“æ„"""
    print("\nğŸ“Š æ£€æŸ¥ PostgreSQL æ•°æ®åº“...")

    try:
        pg = get_postgres_client()

        # æ£€æŸ¥è¿æ¥
        result = pg.execute_query("SELECT version()")
        if result:
            print("  âœ… PostgreSQL è¿æ¥æˆåŠŸ")
            print(f"     ç‰ˆæœ¬: {result[0]['version'].split(',')[0]}")

        # æ£€æŸ¥å¿…éœ€çš„è¡¨
        tables = {
            "tweets": [
                "tweet_id", "author", "content", "published_at",
                "tweet_url", "media_urls", "has_media", "processing_status"
            ],
            "watched_users": ["username", "display_name", "priority", "is_active", "notes"],
            "processed_tweets": [
                "tweet_id", "grade", "summary_cn", "keywords",
                "translated_content", "embedding", "processing_time_ms"
            ],
            "tag_definitions": ["category", "name", "weight"],
            "processing_logs": ["tweet_id", "stage", "status"]
        }

        for table_name, expected_columns in tables.items():
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            query = """
            SELECT column_name
            FROM information_schema.columns
            WHERE table_name = %s
            ORDER BY ordinal_position
            """
            columns = pg.execute_query(query, (table_name,))

            if not columns:
                print(f"  âŒ è¡¨ '{table_name}' ä¸å­˜åœ¨")
                continue

            column_names = [col['column_name'] for col in columns]
            print(f"  âœ… è¡¨ '{table_name}' å­˜åœ¨ ({len(column_names)} ä¸ªå­—æ®µ)")

            # æ£€æŸ¥å…³é”®å­—æ®µ
            missing_columns = [col for col in expected_columns if col not in column_names]
            if missing_columns:
                print(f"     âš ï¸  ç¼ºå°‘å­—æ®µ: {', '.join(missing_columns)}")
            else:
                print(f"     âœ… æ‰€æœ‰å…³é”®å­—æ®µå­˜åœ¨")

        # æ£€æŸ¥ processing_status æšä¸¾ç±»å‹
        enum_query = """
        SELECT enumlabel
        FROM pg_enum
        JOIN pg_type ON pg_enum.enumtypid = pg_type.oid
        WHERE pg_type.typname = 'processing_status_enum'
        ORDER BY enumsortorder
        """
        enum_values = pg.execute_query(enum_query)

        if enum_values:
            values = [row['enumlabel'] for row in enum_values]
            print(f"  âœ… æšä¸¾ç±»å‹ 'processing_status_enum' å­˜åœ¨")
            print(f"     å€¼: {', '.join(values)}")
        else:
            print(f"  âŒ æšä¸¾ç±»å‹ 'processing_status_enum' ä¸å­˜åœ¨")

        # æ£€æŸ¥ processed_tweets è¡¨çš„ grade å­—æ®µçº¦æŸ
        constraint_query = """
        SELECT conname, pg_get_constraintdef(oid) as condef
        FROM pg_constraint
        WHERE conrelid = 'processed_tweets'::regclass
        AND contype = 'c'
        """
        constraints = pg.execute_query(constraint_query)

        if constraints:
            for constraint in constraints:
                if 'grade' in constraint['condef']:
                    print(f"  âœ… grade å­—æ®µçº¦æŸå­˜åœ¨")
                    if 'P0' in constraint['condef'] and 'P6' in constraint['condef']:
                        print(f"     âœ… ä½¿ç”¨ P0-P6 åˆ†çº§ç³»ç»Ÿ")
                    else:
                        print(f"     âš ï¸  å¯èƒ½ä½¿ç”¨æ—§çš„ A-F åˆ†çº§ç³»ç»Ÿ")

        return True

    except Exception as e:
        print(f"  âŒ PostgreSQL æ£€æŸ¥å¤±è´¥: {e}")
        return False


def check_redis():
    """æ£€æŸ¥ Redis è¿æ¥"""
    print("\nğŸ“¦ æ£€æŸ¥ Redis ç¼“å­˜...")

    try:
        redis = get_redis_client()

        # æµ‹è¯•è¿æ¥
        redis.set_cache("deployment_check", "ok", expire=10)
        value = redis.get_cache("deployment_check")

        if value == "ok":
            print("  âœ… Redis è¿æ¥æˆåŠŸ")

            # æ£€æŸ¥å®ä¾‹ç¼“å­˜
            instances_key = "nitter:instances:available"
            instances = redis.get_cache(instances_key)

            if instances:
                import json
                instances_data = json.loads(instances)
                print(f"  âœ… Nitter å®ä¾‹ç¼“å­˜å­˜åœ¨ ({len(instances_data)} ä¸ªå®ä¾‹)")
            else:
                print(f"  âš ï¸  Nitter å®ä¾‹ç¼“å­˜ä¸ºç©ºï¼ˆé¦–æ¬¡è¿è¡Œæ­£å¸¸ï¼‰")

            return True
        else:
            print("  âŒ Redis è¯»å†™æµ‹è¯•å¤±è´¥")
            return False

    except Exception as e:
        print(f"  âŒ Redis æ£€æŸ¥å¤±è´¥: {e}")
        return False


def check_llm_config():
    """æ£€æŸ¥ LLM é…ç½®"""
    print("\nğŸ¤– æ£€æŸ¥ LLM é…ç½®...")

    try:
        import os
        from dotenv import load_dotenv
        load_dotenv()

        api_key = os.getenv("LLM_API_KEY")
        api_url = os.getenv("LLM_API_URL", "https://api.openai.com/v1")
        model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")

        if api_key and api_key != "your-api-key":
            print(f"  âœ… LLM_API_KEY å·²é…ç½®")
        else:
            print(f"  âš ï¸  LLM_API_KEY æœªé…ç½®ï¼ˆæ¨æ–‡å¤„ç†åŠŸèƒ½ä¸å¯ç”¨ï¼‰")
            print(f"     è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® LLM_API_KEY")
            return False

        print(f"  â„¹ï¸  LLM_API_URL: {api_url}")
        print(f"  â„¹ï¸  LLM_MODEL: {model}")

        # å°è¯•æµ‹è¯• LLM å®¢æˆ·ç«¯åˆå§‹åŒ–ï¼ˆä¸å®é™…è°ƒç”¨ APIï¼‰
        try:
            from src.processor.llm_client import get_llm_client
            client = get_llm_client()
            print(f"  âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"  âš ï¸  LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"     å¦‚éœ€ä½¿ç”¨æ¨æ–‡å¤„ç†åŠŸèƒ½ï¼Œè¯·æ£€æŸ¥ LLM é…ç½®")
            return False

    except Exception as e:
        print(f"  âš ï¸  LLM é…ç½®æ£€æŸ¥å¤±è´¥: {e}")
        print(f"     å¦‚éœ€ä½¿ç”¨æ¨æ–‡å¤„ç†åŠŸèƒ½ï¼Œè¯·é…ç½® .env æ–‡ä»¶ä¸­çš„ LLM å‚æ•°")
        return False


def check_directories():
    """æ£€æŸ¥å¿…è¦çš„ç›®å½•"""
    print("\nğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„...")

    required_dirs = [
        "logs",
        "data",
        "data/models",
        "migrations",
        "src",
        "src/crawler",
        "src/processor",
        "src/storage",
        "streamlit_app",
        "streamlit_app/pages"
    ]

    all_exist = True
    for dir_path in required_dirs:
        if os.path.exists(dir_path) and os.path.isdir(dir_path):
            print(f"  âœ… {dir_path}/")
        else:
            print(f"  âŒ {dir_path}/ (ä¸å­˜åœ¨)")
            all_exist = False

    return all_exist


def main():
    print("=" * 60)
    print("ğŸš€ Nitter X éƒ¨ç½²éªŒè¯")
    print("=" * 60)

    results = {
        "æ•°æ®åº“": check_database(),
        "Redis": check_redis(),
        "LLMé…ç½®": check_llm_config(),
        "ç›®å½•ç»“æ„": check_directories(),
    }

    print("\n" + "=" * 60)
    print("ğŸ“‹ éªŒè¯ç»“æœæ±‡æ€»")
    print("=" * 60)

    for component, status in results.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"{status_icon} {component}")

    all_passed = all(results.values())

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼éƒ¨ç½²æˆåŠŸï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. æ·»åŠ ç›‘å¬ç”¨æˆ·: python manage_users.py add <username>")
        print("  2. å¯åŠ¨ Streamlit: streamlit run streamlit_app/app.py")
        print("  3. å¯åŠ¨é‡‡é›†: python main.py")
        print("  4. å¯åŠ¨å¤„ç†: python process_worker.py")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè¿›è¡Œä¿®å¤ã€‚")
        print("\nå¸¸è§é—®é¢˜:")
        print("  - æ•°æ®åº“è¿æ¥å¤±è´¥: æ£€æŸ¥ docker-compose æœåŠ¡æ˜¯å¦è¿è¡Œ")
        print("  - è¡¨ä¸å­˜åœ¨: ç¡®è®¤ Docker å®¹å™¨é¦–æ¬¡å¯åŠ¨æ—¶è¿è¡Œäº†åˆå§‹åŒ–è„šæœ¬")
        print("  - LLM é…ç½®é”™è¯¯: æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ LLM_API_KEY é…ç½®")
        return 1


if __name__ == "__main__":
    sys.exit(main())
