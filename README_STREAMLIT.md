# Nitter X 推文采集系统 - Streamlit Web UI

基于 Streamlit 的 Web 管理界面，提供可视化的推文采集系统管理功能。

## 功能特性

### 📊 首页 (app.py)
- **系统概览**: 显示监听用户数、推文总数、今日新增等关键指标
- **数据可视化**:
  - 每日推文趋势图（最近 14 天）
  - Top 10 活跃用户统计
- **快速操作**: 一键跳转到各功能页面
- **系统状态**: 实时显示爬虫运行状态

### 👥 用户管理页面
- **用户列表**:
  - 表格展示所有监听用户
  - 支持排序、筛选、分页
  - 显示用户名、优先级、状态、最后采集时间、推文数等
- **添加用户**:
  - 输入用户名、设置优先级、添加备注
  - 自动验证用户名唯一性
- **编辑用户**:
  - 修改优先级和备注
  - 启用/禁用用户
- **删除用户**:
  - 支持删除用户（推文数据保留）
  - 二次确认防止误删

### 📝 推文展示页面
- **推文列表**:
  - 卡片式展示推文内容
  - 显示作者、内容、发布时间、采集时间
  - 提供原文链接
- **筛选功能**:
  - 按用户筛选
  - 按时间范围筛选（今天、最近3/7/30天、自定义）
  - 关键词搜索
- **分页浏览**:
  - 自定义每页显示数量（10/20/50/100）
  - 页码跳转
- **数据导出**:
  - 导出当前页为 CSV
  - 导出全部数据为 CSV（限制 10000 条）

### ⚙️ 系统监控页面
- **服务状态**:
  - PostgreSQL 连接状态
  - Redis 连接状态
  - 爬虫运行状态
- **系统指标**:
  - 监听用户数、推文总数、今日新增、待处理任务
- **采集趋势**:
  - 最近 30 天推文采集趋势图
- **Nitter 实例**:
  - 显示可用 Nitter 实例列表
  - 显示响应时间
- **系统配置**:
  - 显示当前采集配置参数
  - 显示网络配置参数
- **自动刷新**:
  - 每 10 秒自动刷新页面数据

## 安装依赖

```bash
# 安装 Streamlit 依赖
pip install -r requirements-streamlit.txt
```

## 启动应用

### 方式一：直接启动
```bash
# 启动 Streamlit 应用
streamlit run streamlit_app/app.py

# 指定端口（默认 8501）
streamlit run streamlit_app/app.py --server.port 8502
```

### 方式二：后台启动
```bash
# 后台启动
nohup streamlit run streamlit_app/app.py > logs/streamlit.log 2>&1 &

# 查看日志
tail -f logs/streamlit.log
```

### 方式三：使用配置文件
创建 `.streamlit/config.toml` 配置文件：

```toml
[server]
port = 8501
headless = true
enableCORS = false

[theme]
primaryColor = "#1DA1F2"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
font = "sans serif"
```

然后启动：
```bash
streamlit run streamlit_app/app.py
```

## 访问地址

启动后访问：
- 本地访问: http://localhost:8501
- 局域网访问: http://YOUR_IP:8501

## 目录结构

```
streamlit_app/
├── app.py                    # 主入口（首页）
├── pages/                    # 多页面目录
│   ├── 1_👥_用户管理.py      # 用户管理页面
│   ├── 2_📝_推文展示.py      # 推文展示页面
│   └── 3_⚙️_系统监控.py      # 系统监控页面
├── components/               # 可复用组件（预留）
│   └── __init__.py
└── utils/                    # 工具函数
    ├── __init__.py
    ├── db_helper.py          # 数据库查询辅助
    └── format_helper.py      # 格式化辅助
```

## 使用说明

### 1. 添加监听用户

1. 进入 **用户管理** 页面
2. 点击 **➕ 添加用户** 按钮
3. 输入用户名（不含 @）、设置优先级（1-10）、添加备注（可选）
4. 点击 **✅ 添加** 完成

### 2. 管理用户

1. 在用户列表中选择用户（点击复选框）
2. 可进行以下操作：
   - **启用/禁用**: 控制是否采集该用户
   - **编辑信息**: 修改优先级和备注
   - **删除用户**: 删除监听用户（推文数据保留）

### 3. 浏览推文

1. 进入 **推文展示** 页面
2. 使用筛选器：
   - 选择用户（或查看全部）
   - 选择时间范围
   - 输入关键词搜索
3. 点击 **🔍 应用筛选** 查看结果
4. 使用分页控制浏览推文
5. 可导出数据为 CSV 格式

### 4. 监控系统

1. 进入 **系统监控** 页面
2. 查看服务状态（PostgreSQL、Redis、爬虫）
3. 查看系统指标和采集趋势
4. 查看可用 Nitter 实例列表
5. 页面每 10 秒自动刷新

## 常见问题

### Q: 页面显示 "加载数据失败"
**A**: 请检查：
1. PostgreSQL 是否正常运行
2. Redis 是否正常运行
3. 配置文件 `.env` 中的数据库连接信息是否正确
4. 网络连接是否正常

### Q: 推文列表为空
**A**: 请检查：
1. 是否已添加监听用户
2. 爬虫是否正常运行（`python main.py`）
3. 用户名是否正确
4. 筛选条件是否过于严格

### Q: 如何停止 Streamlit 应用
**A**:
- 前台运行: 按 `Ctrl + C`
- 后台运行: `pkill -f streamlit` 或查找进程 PID 后 `kill PID`

### Q: 自动刷新导致操作中断
**A**: 可以在首页侧边栏关闭 "自动刷新" 选项

### Q: 数据导出失败
**A**:
1. 检查数据量是否过大（超过 10000 条）
2. 尝试使用筛选功能减少数据量
3. 分页导出数据

## 性能优化建议

1. **启用缓存**: 页面已内置缓存机制，减少数据库查询
2. **调整刷新间隔**: 根据实际需求调整自动刷新间隔
3. **限制分页大小**: 推文展示页面建议每页显示 20-50 条
4. **定期清理缓存**: 在侧边栏使用 "🔄 手动刷新" 清理缓存

## 技术栈

- **前端框架**: Streamlit 1.29+
- **数据可视化**: Plotly 5.18+
- **表格组件**: streamlit-aggrid 0.3.4+
- **数据处理**: Pandas 2.0+
- **后端**: PostgreSQL + Redis
- **ORM**: psycopg2

## 开发说明

### 添加新页面

1. 在 `streamlit_app/pages/` 目录下创建新文件
2. 文件命名格式: `序号_emoji_页面名.py`
3. 页面会自动出现在侧边栏导航中

### 添加新组件

1. 在 `streamlit_app/components/` 目录下创建组件文件
2. 定义可复用的 UI 组件函数
3. 在页面中导入使用

### 修改主题

编辑 `.streamlit/config.toml` 文件中的 `[theme]` 部分

## 更新日志

### v1.0.0 (2025-12-22)
- ✅ 实现首页系统概览
- ✅ 实现用户管理页面
- ✅ 实现推文展示页面
- ✅ 实现系统监控页面
- ✅ 支持数据缓存和自动刷新
- ✅ 支持数据导出 (CSV)
- ✅ 支持推文搜索和筛选

## 反馈与支持

如有问题或建议，请提交 Issue 或联系开发团队。
